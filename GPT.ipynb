{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1e268a",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecc3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import math\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a29e11",
   "metadata": {},
   "source": [
    "### Load & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78044ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lyrics.txt','r',encoding='utf-8') as f:\n",
    "    Text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16a6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '/', 'V', '9', 'g', '“', '6', 'u', '!', '*', 's', 'r', 'z', 'h', 'l', 'W', 'a', 'ï', '4', 'Y', 'B', 'w', '?', '(', ')', '\\\\', 'b', 'ó', '5', 'G', '[', 'x', 'E', 'M', '3', 't', 'í', '—', 'F', 'j', 'n', 'i', 'm', 'I', 'c', 'y', 'X', '”', '-', 'A', '&', 'S', '.', ']', 'C', \"'\", 'R', 'p', ':', 'J', 'Z', '1', ',', '7', 'o', 'D', 'k', '0', '2', 'v', '\"', 'H', 'O', ';', 'L', '8', 'P', '’', 'é', 'd', 'T', 'e', 'f', 'K', 'N', 'Q', ' ', 'U', 'q']\n"
     ]
    }
   ],
   "source": [
    "print(list(set(Text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da516f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = Text.replace(\"\\\\\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfa5f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817508"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2123a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6460d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd3e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '/', 'V', '9', 'g', '“', '6', 'u', '!', '*', 's', 'r', 'z', 'h', 'l', 'W', 'a', 'ï', '4', 'Y', 'B', 'w', '?', '(', ')', 'b', 'ó', '5', 'G', '[', 'x', 'E', 'M', '3', 't', 'í', '—', 'F', 'j', 'n', 'i', 'm', 'I', 'c', 'y', 'X', '”', '-', 'A', '&', 'S', '.', ']', 'C', \"'\", 'R', 'p', ':', 'J', 'Z', '1', ',', '7', 'o', 'D', 'k', '0', '2', 'v', '\"', 'H', 'O', ';', 'L', '8', 'P', '’', 'é', 'd', 'T', 'e', 'f', 'K', 'N', 'Q', ' ', 'U', 'q']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2c6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd99b1",
   "metadata": {},
   "source": [
    "### Encode & Decode tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b0c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_to_idx = {c:i for i,c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06f7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_chr = {i:c for i,c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f40860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text:str)->list[int]:\n",
    "    return [chr_to_idx[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48e3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokens:list[int])-> str:\n",
    "    return [idx_to_chr[i] for i in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1e59d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70, 80, 14, 14, 63, 85, 15, 63, 11, 14, 78, 85, 8]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"Hello World !\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55c973e4",
   "metadata": {},
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b2cbb97",
   "metadata": {},
   "source": [
    "vocab_size = tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2124b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = tf.constant(encode(Text))\n",
    "#Data = tf.constant(tokenizer.encode(Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d48351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(817508,), dtype=int32, numpy=array([70, 80, 85, ..., 14, 80, 69])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72c821",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "299176ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self,token,batch,context):\n",
    "        self.token = token\n",
    "        self.batch = batch\n",
    "        self.context = context\n",
    "        self.cur_pos = 0\n",
    "    def get_batch(self):\n",
    "        b,c = self.batch,self.context\n",
    "        start_pos = self.cur_pos\n",
    "        end_pos = self.cur_pos + b*c + 1\n",
    "        add_data = -1\n",
    "        if end_pos > len(self.token):\n",
    "            add_data = end_pos - len(self.token)\n",
    "            end_pos = len(self.token)\n",
    "        d = self.token[start_pos:end_pos]\n",
    "        if add_data != -1:\n",
    "            d = tf.concat([d,self.token[:add_data]],axis=0)\n",
    "        x = tf.reshape(d[:-1],(b,c))\n",
    "        y = tf.reshape(d[1:],(b,c))\n",
    "        self.cur_pos += b*c\n",
    "        if self.cur_pos > len(self.token) - 1:\n",
    "            self.cur_pos=0\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "683abfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH = 16\n",
    "EVAL_BATCH = 8\n",
    "CONTEXT_SIZE = 256\n",
    "train_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22b3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data[:int(len(Data)*train_split)]\n",
    "eval_data = Data[int(len(Data)*train_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39f75b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,TRAIN_BATCH,CONTEXT_SIZE)\n",
    "eval_loader = DataLoader(eval_data,EVAL_BATCH,CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3e491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,xc = train_loader.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f503e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([16, 256]), TensorShape([16, 256]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c87d43ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(16, 256), dtype=int32, numpy=\n",
       " array([[63, 68, 80, ..., 85, 34,  7],\n",
       "        [11, 39, 85, ..., 13, 80, 85],\n",
       "        [34, 40, 41, ...,  7, 10, 34],\n",
       "        ...,\n",
       "        [ 0, 42, 54, ..., 63, 85, 16],\n",
       "        [39, 44, 34, ...,  0, 83, 63],\n",
       "        [25, 63, 78, ..., 85, 16, 34]])>,\n",
       " <tf.Tensor: shape=(16, 256), dtype=int32, numpy=\n",
       " array([[68, 80,  0, ..., 34,  7, 11],\n",
       "        [39, 85, 63, ..., 80, 85, 34],\n",
       "        [40, 41, 80, ..., 10, 34, 85],\n",
       "        ...,\n",
       "        [42, 54, 68, ..., 85, 16, 39],\n",
       "        [44, 34, 13, ..., 83, 63, 25],\n",
       "        [63, 78, 44, ..., 16, 34, 85]])>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.get_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b460f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccdbf72",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "194064aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.Model):\n",
    "    def __init__(self,CONTEXT_SIZE,d_model):\n",
    "        super().__init__()\n",
    "        self.pe = np.zeros((CONTEXT_SIZE,d_model))\n",
    "        self.pos = np.arange(0,CONTEXT_SIZE).reshape(-1,1)\n",
    "        self.div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        self.pe[:, 0::2] = np.sin(self.pos * self.div_term)\n",
    "        self.pe[:, 1::2] = np.cos(self.pos * self.div_term)\n",
    "        self.pe = np.expand_dims(self.pe, axis=0)\n",
    "        self.pos_enc = tf.constant(self.pe, dtype=tf.float32)\n",
    "        print(self.pos_enc.shape)\n",
    "    def call(self,x)->tf.Tensor:\n",
    "        return x + self.pos_enc[:,:tf.shape(x)[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0c33df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.PositionalEncoding at 0x1cfcea2fca0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PositionalEncoding(256,512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c96a5",
   "metadata": {},
   "source": [
    "### Self-Attention"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47fc12f0",
   "metadata": {},
   "source": [
    "class SelfAttention(tf.keras.Model):\n",
    "    def __init__(self,d_model:int):\n",
    "        super().__init__()\n",
    "        self.query = tf.keras.layers.Dense(d_model)\n",
    "        self.key = tf.keras.layers.Dense(d_model)\n",
    "        self.value = tf.keras.layers.Dense(d_model)\n",
    "        self.ff_out = tf.keras.layers.Dense(d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    def call(self,inputs):\n",
    "        B,C,d_model = inputs.shape\n",
    "        Q = self.query(inputs)\n",
    "        K = self.key(inputs)\n",
    "        V = self.value(inputs)\n",
    "        attention_score = tf.matmul(Q,K,transpose_b=True)\n",
    "        mask = tf.cast(tf.linalg.band_part(tf.ones((C,C)),0,-1),tf.bool)\n",
    "        mask = tf.linalg.set_diag(mask,tf.zeros(C,dtype=tf.bool))\n",
    "        attention_score = tf.where(mask,float('-inf'),attention_score)\n",
    "        weighted_attention = tf.nn.softmax(attention_score,axis=-1)\n",
    "        attention_output = tf.matmul(weighted_attention,V)\n",
    "        out = self.ff_out(attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6df3c",
   "metadata": {},
   "source": [
    "### MultiAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f2618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.Model):\n",
    "    def __init__(self,d_model:int,n_heads:int):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // self.n_heads\n",
    "        \n",
    "        assert(self.n_heads * self.head_dim == d_model)\n",
    "        \n",
    "        self.query = tf.keras.layers.Dense(d_model)\n",
    "        self.key = tf.keras.layers.Dense(d_model)\n",
    "        self.value = tf.keras.layers.Dense(d_model)\n",
    "        self.ff_out = tf.keras.layers.Dense(d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    def call(self,inputs):\n",
    "        B,C,d_model = inputs.shape\n",
    "        Q = tf.reshape(self.query(inputs), (B, C, self.n_heads, self.head_dim))\n",
    "        Q = tf.transpose(Q, perm=[0, 2, 1, 3])\n",
    "        K = tf.reshape(self.key(inputs), (B, C, self.n_heads, self.head_dim))\n",
    "        K = tf.transpose(K, perm=[0, 2, 1, 3])\n",
    "        V = tf.reshape(self.value(inputs), (B, C, self.n_heads, self.head_dim))\n",
    "        V = tf.transpose(V, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        attention_score = tf.matmul(Q,K,transpose_b=True)/tf.math.sqrt(float(self.head_dim))\n",
    "        mask = tf.cast(tf.linalg.band_part(tf.ones((C,C)),0,-1),tf.bool)\n",
    "        mask = tf.linalg.set_diag(mask,tf.zeros(C,dtype=tf.bool))\n",
    "        attention_score = tf.where(mask,float('-inf'),attention_score)\n",
    "        weighted_attention = tf.nn.softmax(attention_score,axis=-1)\n",
    "        attention_output = tf.matmul(self.dropout(weighted_attention),V)\n",
    "        attention_output = tf.transpose(attention_output,perm=[0,2,1,3])\n",
    "        attention_output = tf.reshape(attention_output,shape=(B,C,d_model))\n",
    "        out = self.ff_out(attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3d99c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdefc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(tf.keras.Model):\n",
    "    def __init__(self,d_model,n_heads):\n",
    "        super().__init__()\n",
    "        self.ff = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(4*d_model,activation=\"gelu\"),\n",
    "            tf.keras.layers.Dense(d_model)\n",
    "        ])\n",
    "        self.att = MultiHeadAttention(d_model,n_heads)\n",
    "        self.ln1 = tf.keras.layers.LayerNormalization()\n",
    "        self.ln2 = tf.keras.layers.LayerNormalization()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    def call(self,logits):\n",
    "        att_logits = self.att(logits)\n",
    "        adn_logits = self.ln1(logits+att_logits)\n",
    "        logits = self.dropout(adn_logits)\n",
    "        logits = self.ff(logits)\n",
    "        logits = self.ln2(logits+adn_logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00565624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,d_model,n_heads,n_layers):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(vocab_size,d_model)\n",
    "        self.wpe = PositionalEncoding(CONTEXT_SIZE,d_model)\n",
    "        self.blocks = [DecoderBlock(d_model,n_heads) for _ in range(n_layers)]\n",
    "        self.ff1 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(vocab_size)\n",
    "        ])\n",
    "    def call(self,inputs,targets = None,training=False):\n",
    "        logits = self.emb(inputs)\n",
    "        logits = self.wpe.call(logits)\n",
    "        for block in self.blocks:\n",
    "            logits = block(logits)\n",
    "        logits = self.ff1(logits)\n",
    "        loss = 0\n",
    "        if targets is not None:\n",
    "            batch,seq,d_model = tf.shape(logits)[0],tf.shape(logits)[1],tf.shape(logits)[2]\n",
    "            logits = tf.reshape(logits,[batch*seq,d_model])\n",
    "            targets = tf.reshape(targets,[batch*seq])\n",
    "            loss_fn = tf.keras.losses.sparse_categorical_crossentropy(targets,logits,from_logits=True)\n",
    "            loss = tf.reduce_mean(loss_fn)\n",
    "        return logits,loss\n",
    "    def generate(self,inputs,max_token_num):\n",
    "        output = tf.Variable(inputs)\n",
    "        for _ in range(max_token_num):\n",
    "            curr_seq_len = output.shape[1]\n",
    "            if curr_seq_len > CONTEXT_SIZE:\n",
    "                inputs = inputs[:,-CONTEXT_SIZE:]\n",
    "            logits,_ = self.call(inputs)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = tf.keras.activations.softmax(logits,axis=-1)\n",
    "            idx = tf.random.categorical(tf.math.log(probs),num_samples=1,dtype=tf.int32)\n",
    "            inputs = tf.concat([inputs,idx],axis=-1)\n",
    "            output = tf.concat([output,idx],axis=-1)\n",
    "        return [out for out in output]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5c01288",
   "metadata": {},
   "source": [
    "class SLM(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,d_model,n_heads):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(vocab_size,d_model)\n",
    "        self.wpe = PositionalEncoding(CONTEXT_SIZE,d_model)\n",
    "        self.ff = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(4*d_model,activation=\"gelu\"),\n",
    "            tf.keras.layers.Dense(d_model)\n",
    "        ])\n",
    "        #self.att = SelfAttention(d_model)\n",
    "        self.att = MultiHeadAttention(d_model,n_heads)\n",
    "        self.ln1 = tf.keras.layers.LayerNormalization()\n",
    "        self.ln2 = tf.keras.layers.LayerNormalization()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.ff1 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(vocab_size)\n",
    "        ])\n",
    "    def call(self,inputs,targets = None,training=False):\n",
    "        logits = self.emb(inputs)\n",
    "        logits = self.wpe.call(logits)\n",
    "        att_logits = self.att(logits)\n",
    "        adn_logits = self.ln1(logits+att_logits)\n",
    "        logits = self.dropout(adn_logits)\n",
    "        logits = self.ff(logits)\n",
    "        logits = self.ln2(logits+adn_logits)\n",
    "        logits = self.ff1(logits)\n",
    "        loss = 0\n",
    "        if targets is not None:\n",
    "            batch,seq,d_model = tf.shape(logits)[0],tf.shape(logits)[1],tf.shape(logits)[2]\n",
    "            logits = tf.reshape(logits,[batch*seq,d_model])\n",
    "            targets = tf.reshape(targets,[batch*seq])\n",
    "            loss_fn = tf.keras.losses.sparse_categorical_crossentropy(targets,logits,from_logits=True)\n",
    "            loss = tf.reduce_mean(loss_fn)\n",
    "        return logits,loss\n",
    "    def generate(self,inputs,max_token_num):\n",
    "        output = tf.Variable(inputs)\n",
    "        for _ in range(max_token_num):\n",
    "            curr_seq_len = output.shape[1]\n",
    "            if curr_seq_len > CONTEXT_SIZE:\n",
    "                inputs = inputs[:,-CONTEXT_SIZE:]\n",
    "            logits,_ = self.call(inputs)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = tf.keras.activations.softmax(logits,axis=-1)\n",
    "            idx = tf.random.categorical(tf.math.log(probs),num_samples=1,dtype=tf.int32)\n",
    "            inputs = tf.concat([inputs,idx],axis=-1)\n",
    "            output = tf.concat([output,idx],axis=-1)\n",
    "        return [out for out in output]\n",
    "        #return [decode(out.numpy().tolist()) for out in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a61178e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=256\n",
    "n_heads = 4\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c273df4",
   "metadata": {},
   "source": [
    "m = SLM(vocab_size,d_model,n_heads=n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24a697c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "m = GPT(vocab_size,d_model,n_heads,n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d386f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  22528     \n",
      "                                                                 \n",
      " positional_encoding_1 (Posi  multiple                 0 (unused)\n",
      " tionalEncoding)                                                 \n",
      "                                                                 \n",
      " decoder_block (DecoderBlock  multiple                 789760    \n",
      " )                                                               \n",
      "                                                                 \n",
      " decoder_block_1 (DecoderBlo  multiple                 789760    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (16, 256, 88)             22616     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,624,664\n",
      "Trainable params: 1,624,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.build(input_shape=(16, 256))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245fe40",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c948084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 \ttrain_loss: 1.665138602256775 \teval_loss: 1.7025821208953857\n",
      "Epoch: 4000 \ttrain_loss: 1.2841722965240479 \teval_loss: 1.381739616394043\n",
      "Epoch: 6000 \ttrain_loss: 1.2152273654937744 \teval_loss: 1.7053344249725342\n",
      "Epoch: 8000 \ttrain_loss: 0.9449632167816162 \teval_loss: 2.155064105987549\n",
      "Epoch: 10000 \ttrain_loss: 1.0582729578018188 \teval_loss: 2.0462427139282227\n",
      "Epoch: 12000 \ttrain_loss: 0.7053725719451904 \teval_loss: 1.3840622901916504\n",
      "Epoch: 14000 \ttrain_loss: 0.9804032444953918 \teval_loss: 1.7156836986541748\n",
      "Epoch: 16000 \ttrain_loss: 0.5309898853302002 \teval_loss: 3.0305087566375732\n",
      "Epoch: 18000 \ttrain_loss: 0.6560888886451721 \teval_loss: 4.168720245361328\n",
      "Epoch: 20000 \ttrain_loss: 0.40707501769065857 \teval_loss: 2.455336809158325\n",
      "Epoch: 22000 \ttrain_loss: 0.4803198277950287 \teval_loss: 2.6075375080108643\n",
      "Epoch: 24000 \ttrain_loss: 0.3484504520893097 \teval_loss: 2.27535080909729\n",
      "Epoch: 26000 \ttrain_loss: 0.36934056878089905 \teval_loss: 2.26998233795166\n",
      "Epoch: 28000 \ttrain_loss: 0.2604224681854248 \teval_loss: 3.4044504165649414\n",
      "Epoch: 30000 \ttrain_loss: 0.34379488229751587 \teval_loss: 4.365389347076416\n",
      "Epoch: 32000 \ttrain_loss: 0.23429842293262482 \teval_loss: 3.2261087894439697\n",
      "Epoch: 34000 \ttrain_loss: 0.2524086833000183 \teval_loss: 3.3035717010498047\n",
      "Epoch: 36000 \ttrain_loss: 0.19022977352142334 \teval_loss: 2.290944814682007\n",
      "Epoch: 38000 \ttrain_loss: 0.2199045568704605 \teval_loss: 5.550212860107422\n",
      "Epoch: 40000 \ttrain_loss: 0.16778677701950073 \teval_loss: 2.5541632175445557\n",
      "Epoch: 42000 \ttrain_loss: 0.17192432284355164 \teval_loss: 3.0473673343658447\n",
      "Epoch: 44000 \ttrain_loss: 0.14001595973968506 \teval_loss: 4.291987419128418\n",
      "Epoch: 46000 \ttrain_loss: 0.16075077652931213 \teval_loss: 4.019361972808838\n",
      "Epoch: 48000 \ttrain_loss: 0.12140347063541412 \teval_loss: 5.976786136627197\n",
      "Epoch: 50000 \ttrain_loss: 0.13456769287586212 \teval_loss: 4.700984001159668\n",
      "Epoch: 52000 \ttrain_loss: 0.11990609019994736 \teval_loss: 7.519254207611084\n",
      "Epoch: 54000 \ttrain_loss: 0.13393986225128174 \teval_loss: 7.38372802734375\n",
      "Epoch: 56000 \ttrain_loss: 0.12104235589504242 \teval_loss: 1.9009451866149902\n",
      "Epoch: 58000 \ttrain_loss: 0.1263572871685028 \teval_loss: 4.316729545593262\n",
      "Epoch: 60000 \ttrain_loss: 0.0983944833278656 \teval_loss: 4.342623710632324\n",
      "Epoch: 62000 \ttrain_loss: 0.10258893668651581 \teval_loss: 4.057799816131592\n",
      "Epoch: 64000 \ttrain_loss: 0.10215527564287186 \teval_loss: 4.357629776000977\n",
      "Epoch: 66000 \ttrain_loss: 0.10321561247110367 \teval_loss: 7.401074409484863\n",
      "Epoch: 68000 \ttrain_loss: 0.08947975933551788 \teval_loss: 4.2824249267578125\n",
      "Epoch: 70000 \ttrain_loss: 0.09446679800748825 \teval_loss: 3.9970219135284424\n",
      "Epoch: 72000 \ttrain_loss: 0.09029160439968109 \teval_loss: 4.691289901733398\n",
      "Epoch: 74000 \ttrain_loss: 0.09686538577079773 \teval_loss: 4.706921100616455\n",
      "Epoch: 76000 \ttrain_loss: 0.08312449604272842 \teval_loss: 2.5238728523254395\n",
      "Epoch: 78000 \ttrain_loss: 0.10517153143882751 \teval_loss: 4.714378356933594\n",
      "Epoch: 80000 \ttrain_loss: 0.09501268714666367 \teval_loss: 6.509639263153076\n",
      "Epoch: 82000 \ttrain_loss: 0.08040492236614227 \teval_loss: 5.274999618530273\n",
      "Epoch: 84000 \ttrain_loss: 0.0722559317946434 \teval_loss: 2.303696632385254\n",
      "Epoch: 86000 \ttrain_loss: 0.08334469795227051 \teval_loss: 5.001986980438232\n",
      "Epoch: 88000 \ttrain_loss: 0.07544629275798798 \teval_loss: 4.196245193481445\n",
      "Epoch: 90000 \ttrain_loss: 0.08536704629659653 \teval_loss: 5.175603866577148\n",
      "Epoch: 92000 \ttrain_loss: 0.06735867261886597 \teval_loss: 3.8553388118743896\n",
      "Epoch: 94000 \ttrain_loss: 0.07802418619394302 \teval_loss: 5.319151878356934\n",
      "Epoch: 96000 \ttrain_loss: 0.07020159065723419 \teval_loss: 2.475247859954834\n",
      "Epoch: 98000 \ttrain_loss: 0.07525578886270523 \teval_loss: 1.9142827987670898\n",
      "Epoch: 100000 \ttrain_loss: 0.07547194510698318 \teval_loss: 3.333599805831909\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "eval_steps = 2000\n",
    "learning_rate=1e-3\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "for i in range(1,epochs+1):\n",
    "    xb,xc = train_loader.get_batch()\n",
    "    with tf.GradientTape() as tape:\n",
    "        logit,loss = m.call(xb,xc,training=True)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss,m.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads,m.trainable_variables))\n",
    "    if i%eval_steps == 0:\n",
    "        yb,yc = eval_loader.get_batch()\n",
    "        _,e_loss = m.call(yb,yc,training=False)\n",
    "        e_loss = tf.reduce_mean(e_loss)\n",
    "        print(f\"Epoch: {i} \\ttrain_loss: {loss.numpy()} \\teval_loss: {e_loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1b5562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.convert_to_tensor(encode(\"Love\"))\n",
    "inputs = tf.expand_dims(inputs,axis=1)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eea9334c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes to no-rist-ohead)\n",
      "Flows, it's deal\n",
      "If I told you I'm in your Aring all their giving the joke, no oh-oh, oh-oh!\n",
      "You need it back now, it's just because of your choses, as songs specklues, inside she wastling on None innoce\n",
      "You littee like the Car, lights before you (Grew push my!\n",
      "Tellization)\n",
      "And I sat u2019s so gone, I'm cay\n",
      "\n",
      "Set the right tears back when you were like me, wide\n",
      "I as I lock believe, and mark for a lie\"\n",
      "Tin' ain't not the go dirl shooding even known I'm who it to flame\n",
      "Theed I thould something, I see fire, I feit lacking flictrees, that a finning an acheice from the song all the sunset ends\n",
      "And I'll got see fireing and don't see\n",
      "(You will blood, I was scream, and reason\n",
      "Whrisping up, my farm room, and restimatuallate, in the aird shoulder and reason\n",
      "Itu2019ll the same, he don't wanna him from him to time, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh\n",
      "\n",
      "It we were right the wrap, weep your of the sick, and reason leave foxist pure I set think that I donu2019t keep me?\n",
      "A hang\n"
     ]
    }
   ],
   "source": [
    "print(''.join(decode(m.generate(inputs,1000)[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3130e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "word = tf.convert_to_tensor(encode(\"sweet\"))\n",
    "word = tf.expand_dims(word,axis=1)\n",
    "print(word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c88a2368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s,\n",
      "I was tired and fell asleep beneath an oak tree,\n",
      "I bet my mother's proud of me from each scar,\n",
      "Upon my knuckle and each graze upon my knew moth-My,\n",
      "my prives heart,\n",
      "I don't wanna got dechood on the fam wide and he how let\n",
      "We mad,\n",
      "on not let their problem,\n",
      "You so,\n",
      "He's the top And by myself to fly on the fucky to pain interwatorner someo,\n",
      "And if the night,\n",
      "If I shouldn't\n",
      "Bull only the I'll be enough\n",
      "We people more Friends just on all over night far\n",
      "Cause you are my one mornth.,\n",
      "And I sat of high my soul\n",
      "If you now,\n",
      "You're happy on the flames be my brothers,\n",
      "Tell me when it,\n",
      "Write tinger around,\n",
      "Tonight,\n",
      "At give me that come back would you do,\n",
      "\n",
      "Oh,\n",
      "my,\n",
      "my seem,\n",
      "And I see fible faded it,\n",
      "It's a hard,\n",
      "And if you'll put me when you were hon thinkin'\n",
      "And it's too so gorday someoke down,\n",
      "Tryin' to go Eydoyes,\n",
      "I to be sometimes I won't have faded,\n",
      "But at the light we would wait,\n",
      "There more times,\n",
      "Stayin' help it celebelieve,\n",
      "I lost you though,\n",
      "I have to raina,\n",
      "And I'll piet,\n",
      "u2019s should re\n"
     ]
    }
   ],
   "source": [
    "print(''.join(decode(m.generate(word,1000)[0].numpy().tolist())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_AI",
   "language": "python",
   "name": "ml_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
